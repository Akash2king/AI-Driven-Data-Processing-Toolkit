
# ğŸ“Š LLM-Guided Survey Data Cleaning and Preparation Tool

A **comprehensive web-based interactive system** that uses **machine learning** to generate metadata about survey datasets and employs a **Large Language Model (LLM)** to decide, verify, and control the execution of cleaning and processing steps â€” all with **step-by-step user acknowledgment** and **persistent memory** for quality assurance and reproducibility.

---

## ğŸš€ Features

### ğŸ§  Core Capabilities

* **Automated Data Analysis** â€“ AI-powered detection of missing values, duplicates, outliers, and data quality issues.
* **LLM-Guided Decision Making** â€“ GPT-4 or Llama-3 powered recommendations for cleaning steps.
* **Interactive Step Approval** â€“ Users can approve, reject, or modify each cleaning action.
* **Comprehensive Reporting** â€“ Before/after analysis with exportable cleaning reports.
* **Survey Weight Detection** â€“ Automatic identification of survey weight variables.
* **Quality Scoring** â€“ Real-time data quality assessment and improvement tracking.

### âš™ï¸ Technical Features

* **Scalable Architecture** â€“ Stateless **FastAPI** backend with modular design.
* **Multiple File Formats** â€“ Supports CSV, Excel (.xlsx, .xls), and SPSS (.sav).
* **Persistent Memory** â€“ PostgreSQL storage for step history and LLM memory.
* **Real-time Verification** â€“ LLM validates the effectiveness of each cleaning step.
* **Flexible Export Options** â€“ Clean datasets exportable in multiple formats.

---

## ğŸ—ï¸ System Architecture

### ğŸ–¥ï¸ Backend (FastAPI + Python)

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ modules/          # Core processing modules
â”‚   â”‚   â”œâ”€â”€ data_upload.py
â”‚   â”‚   â”œâ”€â”€ metadata_generator.py
â”‚   â”‚   â”œâ”€â”€ llm_controller.py
â”‚   â”‚   â”œâ”€â”€ ml_processors.py
â”‚   â”‚   â””â”€â”€ report_generator.py
â”‚   â”œâ”€â”€ api/              # API endpoints
â”‚   â”œâ”€â”€ core/             # Config & DB setup
â”‚   â”œâ”€â”€ models/           # Database models
â”‚   â””â”€â”€ utils/            # Utility functions
â”œâ”€â”€ main.py               # FastAPI entrypoint
â””â”€â”€ requirements.txt      # Dependencies
```

### ğŸŒ Frontend (React + TypeScript)

```
frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/       # UI Components
â”‚   â”‚   â”œâ”€â”€ FileUpload.tsx
â”‚   â”‚   â”œâ”€â”€ DataPreview.tsx
â”‚   â”‚   â”œâ”€â”€ StepApprovalModal.tsx
â”‚   â”‚   â”œâ”€â”€ StepExecutionLog.tsx
â”‚   â”‚   â””â”€â”€ FinalReportView.tsx
â”‚   â”œâ”€â”€ pages/            # App Pages
â”‚   â”œâ”€â”€ types/            # TS Types
â”‚   â”œâ”€â”€ utils/            # API Helpers
â”‚   â””â”€â”€ App.tsx           # Main App Component
â””â”€â”€ package.json          # Node.js dependencies
```

---

## ğŸ› ï¸ Installation & Setup

### âœ… Prerequisites

* Python **3.8+**
* Node.js **16+**
* PostgreSQL **12+**
* Redis **6+** *(optional, for caching)*

---

### ğŸ”§ Backend Setup

```bash
cd backend
python -m venv venv
# Activate environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

pip install -r requirements.txt
cp .env.example .env  # Edit configuration
```

1. **Configure Database**

   * Create a PostgreSQL database.
   * Update `DATABASE_URL` in `.env`.
   * Run migrations (auto-created on startup).

2. **Start Backend**

```bash
python main.py
```

API will be available at **[http://localhost:8000](http://localhost:8000)**

---

### ğŸ¨ Frontend Setup

```bash
cd frontend
npm install
npm start
```

Frontend will be available at **[http://localhost:3000](http://localhost:3000)**

---

## ğŸ”§ Configuration

### `.env` Example

```env
DATABASE_URL=postgresql://user:password@localhost:5432/survey_cleaner
REDIS_URL=redis://localhost:6379

# LLM
OPENAI_API_KEY=your-openai-api-key
OPENAI_MODEL=gpt-4
LLM_PROVIDER=openai  # or 'local'

UPLOAD_DIR=./data/uploads
MAX_FILE_SIZE=104857600  # 100MB
SECRET_KEY=your-super-secret-key
```

### LLM Options

* **OpenAI GPT-4 (Recommended):** `LLM_PROVIDER=openai`
* **Local Llama-3:** `LLM_PROVIDER=local` + configure `LOCAL_LLM_URL`

---

## ğŸ“Š Data Processing Pipeline

1. **Upload & Analyze**

   * File upload & validation
   * Metadata & quality score generation

2. **LLM Decision Making**

   * Recommendations for cleaning steps
   * Method selection based on dataset

3. **Interactive Cleaning**

   * Step-by-step user approval
   * Execution logs & live verification

4. **Quality Assurance**

   * Before/after comparison
   * Improvement tracking & lineage logs

5. **Reporting**

   * Generate and export final cleaning report

---

## ğŸ¯ Supported Cleaning Operations

* **Duplicates:** Exact, near-match, fuzzy deduplication
* **Missing Values:** KNN, RF, statistical imputation
* **Outliers:** IQR, Z-score, Isolation Forest, LOF
* **Data Types:** Auto-detection & type conversion
* **Survey-Specific:** Weight detection, weighted stats, design effect analysis

---

## ğŸš€ Example API Workflow

```python
# Upload Dataset
POST /api/v1/cleaning/upload

# Create Session
POST /api/v1/cleaning/dataset/{dataset_id}/session

# Get LLM Recommendation
POST /api/v1/cleaning/session/{session_id}/next-step

# Execute Cleaning Step
POST /api/v1/cleaning/session/{session_id}/execute-step
```

Full documentation: **[http://localhost:8000/docs](http://localhost:8000/docs)**

---

## ğŸ§ª Testing

```bash
# Backend
cd backend
pytest

# Frontend
cd frontend
npm test
```

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Commit & push changes
4. Submit a PR

---

## ğŸ“ License

Licensed under **MIT License** â€“ see [LICENSE](LICENSE).

---

## ğŸ™ Acknowledgments

* **OpenAI** â€“ GPT-4 API
* **Meta** â€“ Llama-3 architecture
* **FastAPI & React** communities
* Survey research domain experts

---

## ğŸ“ Support

* Open a GitHub issue
* Check `/docs`
* Review API at `/api/docs`

---

**Built with â¤ï¸ for the survey research community**
